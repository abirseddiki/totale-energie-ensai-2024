{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6871c81e-056c-47e5-8c4e-ace4e65fe9bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43937a43-1a3d-494a-85bd-2a7ab7c20e1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.6023666\ttotal: 804ms\tremaining: 6m 41s\n",
      "100:\tlearn: 1.3965961\ttotal: 1m 19s\tremaining: 5m 12s\n",
      "200:\tlearn: 1.2843273\ttotal: 2m 38s\tremaining: 3m 55s\n",
      "300:\tlearn: 1.2201498\ttotal: 3m 57s\tremaining: 2m 36s\n",
      "400:\tlearn: 1.1755212\ttotal: 5m 15s\tremaining: 1m 17s\n",
      "499:\tlearn: 1.1414569\ttotal: 6m 33s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Catboost has built-in feature importance\n",
    "from catboost import CatBoostClassifier\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Concatenate Plug States for Classification\n",
    "def concatenate_states(df):\n",
    "    # Concatenate 'Available', 'Charging', 'Passive', 'Other' into a single string\n",
    "    df['plug_state'] = df.apply(lambda row: f\"{row['Available']}{row['Charging']}{row['Passive']}{row['Other']}\", axis=1)\n",
    "    return df\n",
    "\n",
    "# Concatenate plug states for classification\n",
    "data = concatenate_states(data)\n",
    "\n",
    "# Prepare features and target\n",
    "data['Postcode'] = data['Postcode'].astype(str)\n",
    "data['area'] = data['area'].astype('category')\n",
    "\n",
    "# Select relevant features for training\n",
    "X = data[['tod', 'dow', 'trend', 'Latitude', 'Longitude', 'Postcode', 'area']]\n",
    "y = data['plug_state']  # Target variable (concatenated plug states)\n",
    "\n",
    "# Instantiate CatBoostClassifier\n",
    "model = CatBoostClassifier(iterations=500, learning_rate=0.1, depth=6, loss_function='MultiClass', task_type=\"GPU\", verbose=100)\n",
    "\n",
    "# Train the model with categorical features specified\n",
    "model.fit(X, y, cat_features=['Postcode', 'area'])\n",
    "\n",
    "# Retrieve feature importance scores\n",
    "feature_importances = model.get_feature_importance()\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create a DataFrame for feature importance scores\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.title('Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21ec2ebb-981f-4001-9268-c9c36a901cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark Accuracy (Median Prediction): 0.3810\n"
     ]
    }
   ],
   "source": [
    "# Simple linear model benchmark with all features\n",
    "# Benchmark Accuracy (Median Prediction): 0.3810\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Concatenate Plug States for Classification\n",
    "def concatenate_states(df):\n",
    "    df['plug_state'] = df.apply(lambda row: f\"{row['Available']}{row['Charging']}{row['Passive']}{row['Other']}\", axis=1)\n",
    "    return df\n",
    "\n",
    "# Function to calculate the median benchmark accuracy\n",
    "def calculate_median_benchmark(y_train, y_test):\n",
    "    # Get the most common class in the training set (mode)\n",
    "    median_benchmark = y_train.mode()[0]\n",
    "    # Predict this common class for all test samples\n",
    "    y_pred_median = [median_benchmark] * len(y_test)\n",
    "    # Calculate and return accuracy\n",
    "    return accuracy_score(y_test, y_pred_median)\n",
    "\n",
    "# Assuming 'data' is your DataFrame\n",
    "data = concatenate_states(data)\n",
    "\n",
    "# Prepare features and target for plug_state prediction\n",
    "X = data[['tod', 'dow', 'trend', 'Latitude', 'Longitude', 'Postcode', 'area']]\n",
    "y = data['plug_state']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X_encoded = pd.get_dummies(X, columns=['Postcode', 'area'], drop_first=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Calculate the median benchmark accuracy\n",
    "median_accuracy = calculate_median_benchmark(y_train, y_test)\n",
    "print(f'Benchmark Accuracy (Median Prediction): {median_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9511de6c-8395-448a-984f-85263446274d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark Accuracy (Median Prediction): 0.3810\n"
     ]
    }
   ],
   "source": [
    "# Simple linear model for benchmark - take out 3 least important features\n",
    "# Benchmark Accuracy (Median Prediction): 0.3810\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Concatenate Plug States for Classification\n",
    "def concatenate_states(df):\n",
    "    df['plug_state'] = df.apply(lambda row: f\"{row['Available']}{row['Charging']}{row['Passive']}{row['Other']}\", axis=1)\n",
    "    return df\n",
    "\n",
    "# Function to calculate the median benchmark accuracy\n",
    "def calculate_median_benchmark(y_train, y_test):\n",
    "    # Get the most common class in the training set (mode)\n",
    "    median_benchmark = y_train.mode()[0]\n",
    "    # Predict this common class for all test samples\n",
    "    y_pred_median = [median_benchmark] * len(y_test)\n",
    "    # Calculate and return accuracy\n",
    "    return accuracy_score(y_test, y_pred_median)\n",
    "\n",
    "# Assuming 'data' is your DataFrame\n",
    "data = concatenate_states(data)\n",
    "\n",
    "# Prepare features and target for plug_state prediction\n",
    "X = data[['trend', 'Latitude', 'Longitude', 'Postcode']]\n",
    "y = data['plug_state']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X_encoded = pd.get_dummies(X, columns=['Postcode'], drop_first=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Calculate the median benchmark accuracy\n",
    "median_accuracy = calculate_median_benchmark(y_train, y_test)\n",
    "print(f'Benchmark Accuracy (Median Prediction): {median_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d515df3-e436-49d4-9640-9def5352b353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.6028506\ttest: 2.6016831\tbest: 2.6016831 (0)\ttotal: 664ms\tremaining: 11m 3s\n",
      "100:\tlearn: 1.3921838\ttest: 1.3908272\tbest: 1.3908272 (100)\ttotal: 1m 4s\tremaining: 9m 32s\n",
      "200:\tlearn: 1.2835878\ttest: 1.2832797\tbest: 1.2832797 (200)\ttotal: 2m 7s\tremaining: 8m 28s\n",
      "300:\tlearn: 1.2202358\ttest: 1.2207298\tbest: 1.2207298 (300)\ttotal: 3m 11s\tremaining: 7m 25s\n",
      "400:\tlearn: 1.1756866\ttest: 1.1768454\tbest: 1.1768454 (400)\ttotal: 4m 15s\tremaining: 6m 21s\n",
      "500:\tlearn: 1.1400316\ttest: 1.1419525\tbest: 1.1419525 (500)\ttotal: 5m 19s\tremaining: 5m 17s\n",
      "600:\tlearn: 1.1134338\ttest: 1.1160800\tbest: 1.1160800 (600)\ttotal: 6m 22s\tremaining: 4m 13s\n",
      "700:\tlearn: 1.0910191\ttest: 1.0944577\tbest: 1.0944577 (700)\ttotal: 7m 26s\tremaining: 3m 10s\n",
      "800:\tlearn: 1.0713339\ttest: 1.0757084\tbest: 1.0757084 (800)\ttotal: 8m 29s\tremaining: 2m 6s\n",
      "900:\tlearn: 1.0553689\ttest: 1.0602821\tbest: 1.0602821 (900)\ttotal: 9m 33s\tremaining: 1m 2s\n",
      "999:\tlearn: 1.0406431\ttest: 1.0462148\tbest: 1.0462148 (999)\ttotal: 10m 36s\tremaining: 0us\n",
      "bestTest = 1.046214788\n",
      "bestIteration = 999\n",
      "Accuracy: 0.6286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0003       0.81      0.87      0.84     73323\n",
      "        0012       0.87      0.85      0.86       772\n",
      "        0021       0.70      0.62      0.66       571\n",
      "        0030       0.61      0.41      0.49      3423\n",
      "        0102       0.63      0.41      0.50       112\n",
      "        0111       0.83      0.53      0.64       388\n",
      "        0120       0.35      0.17      0.23      1655\n",
      "        0201       0.47      0.20      0.28       366\n",
      "        0210       0.24      0.05      0.09      1672\n",
      "        0300       0.71      0.08      0.14      1018\n",
      "        1002       0.81      0.69      0.74      3732\n",
      "        1011       0.68      0.50      0.58      3416\n",
      "        1020       0.59      0.22      0.32     11615\n",
      "        1101       0.52      0.39      0.44      3141\n",
      "        1110       0.38      0.13      0.19     10581\n",
      "        1200       0.48      0.09      0.15     11585\n",
      "        2001       0.64      0.63      0.63     10203\n",
      "        2010       0.56      0.32      0.41     43133\n",
      "        2100       0.42      0.26      0.32     48454\n",
      "        3000       0.60      0.87      0.71    141057\n",
      "\n",
      "    accuracy                           0.63    370217\n",
      "   macro avg       0.60      0.41      0.46    370217\n",
      "weighted avg       0.61      0.63      0.59    370217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First model with all features included\n",
    "# Accuracy of 0.5964 with 500 iterations\n",
    "# Accuracy of 0.6286 with 1000 iterations\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Concatenate Plug States for Classification\n",
    "def concatenate_states(df):\n",
    "    # Concatenate 'Available', 'Charging', 'Passive', 'Other' into a single string\n",
    "    df['plug_state'] = df.apply(lambda row: f\"{row['Available']}{row['Charging']}{row['Passive']}{row['Other']}\", axis=1)\n",
    "    return df\n",
    "\n",
    "# Concatenate plug states for classification\n",
    "data = concatenate_states(data)\n",
    "\n",
    "# Prepare features and target\n",
    "# Cast 'Postcode' and 'area' to categorical\n",
    "data['Postcode'] = data['Postcode'].astype(str)\n",
    "data['area'] = data['area'].astype('category')\n",
    "\n",
    "# Select relevant features for training\n",
    "X = data[['tod', 'dow', 'trend', 'Latitude', 'Longitude', 'Postcode', 'area']]\n",
    "y = data['plug_state']  # Target variable (concatenated plug states)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train CatBoost Classifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function='MultiClass',\n",
    "    verbose=100,\n",
    "    task_type=\"GPU\",\n",
    "    allow_writing_files=False\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=['Postcode', 'area'],\n",
    "    eval_set=(X_test, y_test),\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "# Make Predictions and Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acae443-209d-4679-a1c9-99205976356d",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ef22ad5-224c-4c0a-9984-957fdd8595f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.6248918\ttest: 2.6238412\tbest: 2.6238412 (0)\ttotal: 588ms\tremaining: 4m 53s\n",
      "100:\tlearn: 1.5113211\ttest: 1.5089817\tbest: 1.5089817 (100)\ttotal: 59s\tremaining: 3m 53s\n",
      "200:\tlearn: 1.4106010\ttest: 1.4089526\tbest: 1.4089526 (200)\ttotal: 1m 57s\tremaining: 2m 54s\n",
      "300:\tlearn: 1.3528048\ttest: 1.3516087\tbest: 1.3516087 (300)\ttotal: 2m 55s\tremaining: 1m 56s\n",
      "400:\tlearn: 1.3123637\ttest: 1.3115045\tbest: 1.3115045 (400)\ttotal: 3m 54s\tremaining: 57.9s\n",
      "499:\tlearn: 1.2807176\ttest: 1.2800445\tbest: 1.2800445 (499)\ttotal: 4m 52s\tremaining: 0us\n",
      "bestTest = 1.280044457\n",
      "bestIteration = 499\n",
      "Accuracy: 0.5519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0003       0.73      0.79      0.76     73323\n",
      "        0012       0.74      0.67      0.70       772\n",
      "        0021       0.87      0.13      0.23       571\n",
      "        0030       0.73      0.25      0.37      3423\n",
      "        0102       0.75      0.03      0.05       112\n",
      "        0111       0.88      0.37      0.52       388\n",
      "        0120       0.27      0.06      0.10      1655\n",
      "        0201       0.47      0.02      0.04       366\n",
      "        0210       0.22      0.03      0.06      1672\n",
      "        0300       0.77      0.05      0.09      1018\n",
      "        1002       0.70      0.48      0.57      3732\n",
      "        1011       0.73      0.15      0.25      3416\n",
      "        1020       0.40      0.08      0.13     11615\n",
      "        1101       0.39      0.12      0.18      3141\n",
      "        1110       0.21      0.03      0.06     10581\n",
      "        1200       0.35      0.03      0.05     11585\n",
      "        2001       0.47      0.23      0.31     10203\n",
      "        2010       0.48      0.18      0.27     43133\n",
      "        2100       0.33      0.13      0.19     48454\n",
      "        3000       0.52      0.88      0.65    141057\n",
      "\n",
      "    accuracy                           0.55    370217\n",
      "   macro avg       0.55      0.23      0.28    370217\n",
      "weighted avg       0.52      0.55      0.49    370217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reduced depth to 4 from 6\n",
    "# Accuracy decreased to 0.5519 with 500 iterations\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Concatenate Plug States for Classification\n",
    "def concatenate_states(df):\n",
    "    # Concatenate 'Available', 'Charging', 'Passive', 'Other' into a single string\n",
    "    df['plug_state'] = df.apply(lambda row: f\"{row['Available']}{row['Charging']}{row['Passive']}{row['Other']}\", axis=1)\n",
    "    return df\n",
    "\n",
    "# Concatenate plug states for classification\n",
    "data = concatenate_states(data)\n",
    "\n",
    "# Prepare features and target\n",
    "# Cast 'Postcode' and 'area' to categorical\n",
    "data['Postcode'] = data['Postcode'].astype(str)\n",
    "data['area'] = data['area'].astype('category')\n",
    "\n",
    "# Select relevant features for training\n",
    "X = data[['tod', 'dow', 'trend', 'Latitude', 'Longitude', 'Postcode', 'area']]\n",
    "y = data['plug_state']  # Target variable (concatenated plug states)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train CatBoost Classifier with adjusted hyperparameters\n",
    "model = CatBoostClassifier(\n",
    "    iterations=500,  \n",
    "    learning_rate=0.1,\n",
    "    depth=4,  # Reduced depth\n",
    "    loss_function='MultiClass',\n",
    "    verbose=100,\n",
    "    task_type=\"GPU\",\n",
    "    allow_writing_files=False,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=['Postcode', 'area'],\n",
    "    eval_set=(X_test, y_test),\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "# Make Predictions and Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ae38f4b-4f3b-4762-8fbf-7726fcdbaa4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.7766403\ttest: 2.7759593\tbest: 2.7759593 (0)\ttotal: 703ms\tremaining: 5m 51s\n",
      "100:\tlearn: 1.4366161\ttest: 1.4353570\tbest: 1.4353570 (100)\ttotal: 1m 10s\tremaining: 4m 39s\n",
      "200:\tlearn: 1.3083907\ttest: 1.3080524\tbest: 1.3080524 (200)\ttotal: 2m 21s\tremaining: 3m 30s\n",
      "300:\tlearn: 1.2380308\ttest: 1.2384915\tbest: 1.2384915 (300)\ttotal: 3m 32s\tremaining: 2m 20s\n",
      "400:\tlearn: 1.1905733\ttest: 1.1918889\tbest: 1.1918889 (400)\ttotal: 4m 43s\tremaining: 1m 9s\n",
      "499:\tlearn: 1.1528768\ttest: 1.1551322\tbest: 1.1551322 (499)\ttotal: 5m 54s\tremaining: 0us\n",
      "bestTest = 1.155132159\n",
      "bestIteration = 499\n",
      "Accuracy: 0.5943\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0003       0.77      0.83      0.80     73323\n",
      "        0012       0.76      0.72      0.74       772\n",
      "        0021       0.74      0.34      0.47       571\n",
      "        0030       0.65      0.34      0.44      3423\n",
      "        0102       0.50      0.04      0.07       112\n",
      "        0111       0.86      0.39      0.53       388\n",
      "        0120       0.32      0.12      0.17      1655\n",
      "        0201       0.51      0.08      0.14       366\n",
      "        0210       0.23      0.05      0.09      1672\n",
      "        0300       0.91      0.07      0.13      1018\n",
      "        1002       0.79      0.61      0.69      3732\n",
      "        1011       0.68      0.33      0.45      3416\n",
      "        1020       0.53      0.14      0.22     11615\n",
      "        1101       0.50      0.25      0.34      3141\n",
      "        1110       0.33      0.08      0.12     10581\n",
      "        1200       0.47      0.05      0.10     11585\n",
      "        2001       0.60      0.45      0.52     10203\n",
      "        2010       0.54      0.26      0.35     43133\n",
      "        2100       0.39      0.19      0.26     48454\n",
      "        3000       0.56      0.88      0.68    141057\n",
      "\n",
      "    accuracy                           0.59    370217\n",
      "   macro avg       0.58      0.31      0.36    370217\n",
      "weighted avg       0.57      0.59      0.54    370217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Manually adjusted hyperparameters \n",
    "# Accuracy slightly decreased to 0.5943 with 500 iterations\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Concatenate Plug States for Classification\n",
    "def concatenate_states(df):\n",
    "    # Concatenate 'Available', 'Charging', 'Passive', 'Other' into a single string\n",
    "    df['plug_state'] = df.apply(lambda row: f\"{row['Available']}{row['Charging']}{row['Passive']}{row['Other']}\", axis=1)\n",
    "    return df\n",
    "\n",
    "# Concatenate plug states for classification\n",
    "data = concatenate_states(data)\n",
    "\n",
    "# Prepare features and target\n",
    "data['Postcode'] = data['Postcode'].astype(str)\n",
    "data['area'] = data['area'].astype('category')\n",
    "\n",
    "X = data[['tod', 'dow', 'trend', 'Latitude', 'Longitude', 'Postcode', 'area']]\n",
    "y = data['plug_state']  # Target variable (concatenated plug states)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train CatBoost Classifier with adjusted hyperparameters\n",
    "model = CatBoostClassifier(\n",
    "    iterations=500,         # Increased iterations for more training\n",
    "    learning_rate=0.05,     # Adjusted learning rate for more gradual learning\n",
    "    depth=8,                # Increased depth for a more complex model\n",
    "    l2_leaf_reg=5,          # Added L2 regularization to reduce overfitting\n",
    "    loss_function='MultiClass',\n",
    "    verbose=100,\n",
    "    task_type=\"GPU\",\n",
    "    allow_writing_files=False\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=['Postcode', 'area'],\n",
    "    eval_set=(X_test, y_test),\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "# Make Predictions and Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "092fce34-0285-4067-943f-9b74145f5283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% GPU memory available for training. Free: 160.8125 Total: 4031.875\n",
      "uncaught exception:\n",
      "    address -> 0x2c569450410\n",
      "    what() -> \"catboost/cuda/cuda_lib/cuda_base.cpp:16: CUDA error 2: out of memory\"\n",
      "    type -> TCatBoostException\n",
      "Application terminated with error: ??+0 (0x752747405B54)\n",
      "??+0 (0x7527474056A2)\n",
      "??+0 (0x75274740297E)\n",
      "??+0 (0x752747402EE9)\n",
      "??+0 (0x7527474045B8)\n",
      "??+0 (0x752746151B42)\n",
      "??+0 (0x7527461519AA)\n",
      "??+0 (0x75275F494AC3)\n",
      "??+0 (0x75275F526850)\n",
      "\n",
      "(NCudaLib::TOutOfMemoryError) catboost/cuda/cuda_lib/memory_pool/stack_like_memory_pool.h:303: Error: Out of memory. Requested 71.56542969 MB; Free 10.96230412 MB\n",
      "uncaught exception:\n",
      "    address -> 0x48717130410\n",
      "    what() -> \"catboost/cuda/cuda_lib/memory_pool/stack_like_memory_pool.h:303: Error: Out of memory. Requested 71.56542969 MB; Free 10.96230412 MB\"\n",
      "    type -> NCudaLib::TOutOfMemoryError\n",
      "Warning: less than 75% GPU memory available for training. Free: 160.8125 Total: 4031.875\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGABRT(-6), SIGABRT(-6)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 55\u001b[0m\n\u001b[1;32m     44\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     45\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mmodel, \n\u001b[1;32m     46\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_dist, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m                 \u001b[38;5;66;03m# Set random state for reproducibility\u001b[39;00m\n\u001b[1;32m     52\u001b[0m )\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Train the model with randomized search\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m random_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \n\u001b[1;32m     56\u001b[0m                   cat_features\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPostcode\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marea\u001b[39m\u001b[38;5;124m'\u001b[39m],  \u001b[38;5;66;03m# Ensure both categorical features are included\u001b[39;00m\n\u001b[1;32m     57\u001b[0m                   eval_set\u001b[38;5;241m=\u001b[39m(X_test, y_test),\n\u001b[1;32m     58\u001b[0m                   early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Get the best parameters and the best score\u001b[39;00m\n\u001b[1;32m     61\u001b[0m best_params \u001b[38;5;241m=\u001b[39m random_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m~/ENTER/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/ENTER/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/ENTER/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1960\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1958\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1959\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1960\u001b[0m     evaluate_candidates(\n\u001b[1;32m   1961\u001b[0m         ParameterSampler(\n\u001b[1;32m   1962\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_distributions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[1;32m   1963\u001b[0m         )\n\u001b[1;32m   1964\u001b[0m     )\n",
      "File \u001b[0;32m~/ENTER/lib/python3.12/site-packages/sklearn/model_selection/_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    963\u001b[0m     )\n\u001b[0;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    966\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    967\u001b[0m         clone(base_estimator),\n\u001b[1;32m    968\u001b[0m         X,\n\u001b[1;32m    969\u001b[0m         y,\n\u001b[1;32m    970\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    971\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    972\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    973\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    974\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    975\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    976\u001b[0m     )\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[1;32m    979\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[1;32m    980\u001b[0m     )\n\u001b[1;32m    981\u001b[0m )\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m     )\n",
      "File \u001b[0;32m~/ENTER/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/ENTER/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m~/ENTER/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/ENTER/lib/python3.12/site-packages/joblib/parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1748\u001b[0m \n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1754\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_error_fast()\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/ENTER/lib/python3.12/site-packages/joblib/parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1789\u001b[0m     error_job\u001b[38;5;241m.\u001b[39mget_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/ENTER/lib/python3.12/site-packages/joblib/parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_or_raise()\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/ENTER/lib/python3.12/site-packages/joblib/parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGABRT(-6), SIGABRT(-6)}"
     ]
    }
   ],
   "source": [
    "# Randomized search - ran out of memory\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Concatenate Plug States for Classification\n",
    "def concatenate_states(df):\n",
    "    # Concatenate 'Available', 'Charging', 'Passive', 'Other' into a single string\n",
    "    df['plug_state'] = df.apply(lambda row: f\"{row['Available']}{row['Charging']}{row['Passive']}{row['Other']}\", axis=1)\n",
    "    return df\n",
    "\n",
    "# Concatenate plug states for classification\n",
    "data = concatenate_states(data)\n",
    "\n",
    "# Prepare features and target\n",
    "data['Postcode'] = data['Postcode'].astype(str)\n",
    "data['area'] = data['area'].astype('category')\n",
    "\n",
    "X = data[['tod', 'dow', 'trend', 'Latitude', 'Longitude', 'Postcode', 'area']]\n",
    "y = data['plug_state']  # Target variable (concatenated plug states)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the CatBoost Classifier\n",
    "model = CatBoostClassifier(\n",
    "    loss_function='MultiClass',\n",
    "    task_type=\"GPU\",\n",
    "    allow_writing_files=False,\n",
    "    verbose=0  # Turn off verbose for the search process\n",
    ")\n",
    "\n",
    "# Define the parameter distribution for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'iterations': randint(500, 1000),         # Randomly choose iterations between 500 and 1000\n",
    "    'learning_rate': uniform(0.01, 0.3),      # Randomly choose learning rate between 0.01 and 0.3\n",
    "    'depth': randint(6, 16),                  # Randomly choose depth between 6 and 16\n",
    "    'l2_leaf_reg': uniform(1, 10),             # Randomly choose L2 regularization parameter between 1 and 10\n",
    "    'border_count': randint(32, 255)          # Randomly choose border_count between 32 and 255\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model, \n",
    "    param_distributions=param_dist, \n",
    "    n_iter=50,                      # Number of random combinations to try\n",
    "    scoring='accuracy',             # Optimize for accuracy\n",
    "    cv=3,                           # 3-fold cross-validation\n",
    "    n_jobs=-1,                      # Use all cores for parallel processing\n",
    "    random_state=42                 # Set random state for reproducibility\n",
    ")\n",
    "\n",
    "# Train the model with randomized search\n",
    "random_search.fit(X_train, y_train, \n",
    "                  cat_features=['Postcode', 'area'],  # Ensure both categorical features are included\n",
    "                  eval_set=(X_test, y_test),\n",
    "                  early_stopping_rounds=50)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Cross-validation Accuracy:\", best_score)\n",
    "\n",
    "# Evaluate the model on the test set with the best found parameters\n",
    "y_pred = random_search.best_estimator_.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy on test set: {accuracy:.4f}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3884aefb-ade0-419a-8824-09d976dd195b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 1296 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1296 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/ensai/ENTER/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/ensai/ENTER/lib/python3.12/site-packages/catboost/core.py\", line 5245, in fit\n    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n  File \"/home/ensai/ENTER/lib/python3.12/site-packages/catboost/core.py\", line 2395, in _fit\n    train_params = self._prepare_train_params(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ensai/ENTER/lib/python3.12/site-packages/catboost/core.py\", line 2275, in _prepare_train_params\n    train_pool = _build_train_pool(X, y, cat_features, text_features, embedding_features, pairs, graph,\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ensai/ENTER/lib/python3.12/site-packages/catboost/core.py\", line 1513, in _build_train_pool\n    train_pool = Pool(X, y, cat_features=cat_features, text_features=text_features, embedding_features=embedding_features, pairs=pairs, graph=graph, weight=sample_weight, group_id=group_id,\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ensai/ENTER/lib/python3.12/site-packages/catboost/core.py\", line 855, in __init__\n    self._init(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, graph, weight,\n  File \"/home/ensai/ENTER/lib/python3.12/site-packages/catboost/core.py\", line 1491, in _init\n    self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, graph, weight,\n  File \"_catboost.pyx\", line 4339, in _catboost._PoolBase._init_pool\n  File \"_catboost.pyx\", line 4391, in _catboost._PoolBase._init_pool\n  File \"_catboost.pyx\", line 4200, in _catboost._PoolBase._init_features_order_layout_pool\n  File \"_catboost.pyx\", line 3083, in _catboost._set_features_order_data_pd_data_frame\n_catboost.CatBoostError: features data: pandas.DataFrame column 'area' has dtype 'category' but is not in  cat_features list\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Fit the grid search\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Best parameters and score\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/ENTER/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/ENTER/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/ENTER/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1573\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/ENTER/lib/python3.12/site-packages/sklearn/model_selection/_search.py:996\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    994\u001b[0m     )\n\u001b[0;32m--> 996\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_score)\n\u001b[1;32m    998\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/ENTER/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 1296 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1296 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/ensai/ENTER/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/ensai/ENTER/lib/python3.12/site-packages/catboost/core.py\", line 5245, in fit\n    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n  File \"/home/ensai/ENTER/lib/python3.12/site-packages/catboost/core.py\", line 2395, in _fit\n    train_params = self._prepare_train_params(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ensai/ENTER/lib/python3.12/site-packages/catboost/core.py\", line 2275, in _prepare_train_params\n    train_pool = _build_train_pool(X, y, cat_features, text_features, embedding_features, pairs, graph,\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ensai/ENTER/lib/python3.12/site-packages/catboost/core.py\", line 1513, in _build_train_pool\n    train_pool = Pool(X, y, cat_features=cat_features, text_features=text_features, embedding_features=embedding_features, pairs=pairs, graph=graph, weight=sample_weight, group_id=group_id,\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ensai/ENTER/lib/python3.12/site-packages/catboost/core.py\", line 855, in __init__\n    self._init(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, graph, weight,\n  File \"/home/ensai/ENTER/lib/python3.12/site-packages/catboost/core.py\", line 1491, in _init\n    self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, graph, weight,\n  File \"_catboost.pyx\", line 4339, in _catboost._PoolBase._init_pool\n  File \"_catboost.pyx\", line 4391, in _catboost._PoolBase._init_pool\n  File \"_catboost.pyx\", line 4200, in _catboost._PoolBase._init_features_order_layout_pool\n  File \"_catboost.pyx\", line 3083, in _catboost._set_features_order_data_pd_data_frame\n_catboost.CatBoostError: features data: pandas.DataFrame column 'area' has dtype 'category' but is not in  cat_features list\n"
     ]
    }
   ],
   "source": [
    "# Grid search - error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Prepare features and target\n",
    "# Cast 'Postcode' and 'area' to categorical\n",
    "data['Postcode'] = data['Postcode'].astype(str)\n",
    "data['area'] = data['area'].astype('category')\n",
    "\n",
    "# Select relevant features for training\n",
    "X = data[['tod', 'dow', 'trend', 'Latitude', 'Longitude', 'Postcode', 'area']]\n",
    "y = data['plug_state']  # Target variable (concatenated plug states)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "model = CatBoostClassifier(loss_function='MultiClass', task_type=\"GPU\", verbose=0)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'iterations': [200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'depth': [4, 5, 6],\n",
    "    'l2_leaf_reg': [3, 5, 10],\n",
    "    'bagging_temperature': [0.5, 1],\n",
    "    'feature_fraction': [0.8, 0.9],\n",
    "    'subsample': [0.7, 0.8]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
